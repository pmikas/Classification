{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Don't call me turkey!</h1>\n",
    "<br>\n",
    "This dataset is based on AudioSet’s data available <a href=\"https://research.google.com/audioset/\">here</a>. The data contains video IDs and time bounds for youtube clips, as well as 128-dimensional audio-based features created with VGGish based on these clips.<br>\n",
    "We must predict if the sound clip from which audio_embedding originates contains a turkey sound.<br>\n",
    "AudioSet's dataset is under a Creative Commons Attribution 4.0 International (CC BY 4.0) license, while their ontology is under a Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) license. Our data includes data from both, modified to fit the <a href=\"https://www.kaggle.com/c/dont-call-me-turkey\">Kaggle</a> competition format.<br>\n",
    "<br>\n",
    "<h3>Objective</h3><br>\n",
    "Find the turkey sound signature from pre-extracted audio features in order to classify the dataset.<br><br>\n",
    "<h3>Content</h3><br>\n",
    "This notebook is divided into:\n",
    "<ol>\n",
    "    <li><a href=\"#basic\">Basic information</a></li>\n",
    "    <li><a href=\"#cleaning\">Data cleaning</a></li>\n",
    "    <li><a href=\"#engineering\">Feature engineering</a></li>\n",
    "    <li><a href=\"#training\">Model training</a></li>\n",
    "    <li><a href=\"#prection\">Prediction</a></li>\n",
    "</ol><br>\n",
    "<h3>File description</h3>\n",
    "<ul>\n",
    "    <li>train.json - training set</li>\n",
    "    <li>test.json - test set</li>\n",
    "    <li>sample_submission.csv - sample submission file in the correct format</li>\n",
    "</ul><br>\n",
    "<h3>Data description</h3>\n",
    "<ul>\n",
    "    <li>vid_id: YouTube video ID associated with this sample</li>\n",
    "    <li>start_time_seconds_youtube_clip: Where in the YouTube video this audio feature starts</li>\n",
    "    <li>end_time_seconds_youtube_clip: Where in the YouTube video this audio feature ends</li>\n",
    "    <li>audio_embedding: Extracted frame-level audio feature, embedded down to 128 dimensions per frame using AudioSet’s VGGish tools available <a href=\"https://github.com/tensorflow/models/tree/master/research/audioset\">here</a></li>\n",
    "    <li>is_turkey: The target: whether or not the original audio clip contained a turkey. Label is a soft label, based on whether or not AudioSet’s ontology labeled this clip with “Turkey”, and may count turkey calls and other related content as being “turkey”. is_turkey is 1 if the clip contains a turkey sound, and 0 if it does not</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:18px\">Import libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy for numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# Pandas for Dataframes\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns',100)\n",
    "\n",
    "# Matplolib for visualization\n",
    "from matplotlib import pyplot as plt\n",
    "# display plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Seaborn for easier visualization\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:18px\">Load files</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('train.json')\n",
    "test = pd.read_json('test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br id=\"basic\">\n",
    "# 1. Basic information\n",
    "Let's first check some informations about the dataset for each loaded file, as:\n",
    "* Dimension\n",
    "* View the first 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of the training set is: (1195, 5) \n",
      "\n",
      "The dimension of the test set is: (1196, 4) \n",
      "\n",
      "First 3 rows of the training set:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_embedding</th>\n",
       "      <th>end_time_seconds_youtube_clip</th>\n",
       "      <th>is_turkey</th>\n",
       "      <th>start_time_seconds_youtube_clip</th>\n",
       "      <th>vid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[172, 34, 216, 110, 208, 46, 95, 66, 161, 125...</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>kDCk3hLIVXo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[169, 20, 165, 102, 205, 62, 110, 103, 211, 1...</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>DPcGzqHoo7Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[148, 8, 138, 60, 237, 48, 121, 108, 145, 177...</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>7yM63MTHh5k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     audio_embedding  \\\n",
       "0  [[172, 34, 216, 110, 208, 46, 95, 66, 161, 125...   \n",
       "1  [[169, 20, 165, 102, 205, 62, 110, 103, 211, 1...   \n",
       "2  [[148, 8, 138, 60, 237, 48, 121, 108, 145, 177...   \n",
       "\n",
       "   end_time_seconds_youtube_clip  is_turkey  start_time_seconds_youtube_clip  \\\n",
       "0                             70          0                               60   \n",
       "1                             40          1                               30   \n",
       "2                            240          1                              230   \n",
       "\n",
       "        vid_id  \n",
       "0  kDCk3hLIVXo  \n",
       "1  DPcGzqHoo7Y  \n",
       "2  7yM63MTHh5k  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe dimensions\n",
    "print('The dimension of the training set is:',train.shape,'\\n')\n",
    "print('The dimension of the test set is:',test.shape,'\\n')\n",
    "print('First 3 rows of the training set:\\n')\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br id=\"preprocessing\">\n",
    "# 2. Data preprocessing\n",
    "\n",
    "Firstly we will divide the dataset into features and target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Function for splitting training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables for the training set\n",
    "X = train.audio_embedding\n",
    "y = train.is_turkey\n",
    "\n",
    "# Create variable for the test set\n",
    "X_test = test.audio_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples:\n",
      " X_train =  956 , y_train =  956 \n",
      " X_val =  239  , y_val =  239\n"
     ]
    }
   ],
   "source": [
    "# Split X and y into train and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# Print number of observations in X_train, X_val, y_train, and y_val\n",
    "print('Number of examples:\\n', 'X_train = ', len(X_train), ', y_train = ', len(y_train),\n",
    "      '\\n X_val = ', len(X_val), ' , y_val = ', len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the audio features to have length 10\n",
    "X_train = pad_sequences(X_train, maxlen=10)\n",
    "X_val = pad_sequences(X_val, maxlen=10)\n",
    "X_test = pad_sequences(X_test, maxlen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train)\n",
    "y_val = np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br id=\"training\">\n",
    "# 3. Model training\n",
    "For the model we will use the Keras library from Tensorflow, through the following steps:\n",
    "1. Layers setup: define the number of layers, number of nodes of each layer, and their respectively activation function\n",
    "2. Compile: define optimizer, loss and metric\n",
    "3. Training: train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:18px\">Import libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Bidirectional, LSTM, BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:18px\">Layers setup</h1><br>\n",
    "The \"keras.layers.Dense\" layers are densely-connected, or fully-connected, neural layers.\n",
    "* The first Dense layer has 128 nodes, with the ReLU as the activation function\n",
    "* The second Dense layer has 10 nodes, which determine through the softmax function, the probability of the current image belong to one of the 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sequential layers\n",
    "model = Sequential([\n",
    "    BatchNormalization(input_shape=(10,128)),\n",
    "    Dropout(0.5),\n",
    "    Bidirectional(LSTM(128, activation='relu')),\n",
    "    Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:18px\">Compile</h1><br>\n",
    "Configures the model for the training.\n",
    "* optimizer: how the model is updated based on the data and its loss function\n",
    "* loss: objective that the model wants to minimize\n",
    "* metrics: monitor the training and test steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training parameters\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a binary classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:18px\">Training</h1><br>\n",
    "Train the model for a given number of iterations (epochs) on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 956 samples, validate on 239 samples\n",
      "Epoch 1/5\n",
      "956/956 [==============================] - 8s 9ms/step - loss: 0.4355 - acc: 0.7510 - val_loss: 1.3735 - val_acc: 0.8619\n",
      "Epoch 2/5\n",
      "956/956 [==============================] - 1s 1ms/step - loss: 0.1681 - acc: 0.9446 - val_loss: 0.6849 - val_acc: 0.9205\n",
      "Epoch 3/5\n",
      "956/956 [==============================] - 1s 1ms/step - loss: 0.1447 - acc: 0.9404 - val_loss: 0.9061 - val_acc: 0.9163\n",
      "Epoch 4/5\n",
      "956/956 [==============================] - 1s 991us/step - loss: 0.1124 - acc: 0.9592 - val_loss: 0.5827 - val_acc: 0.9414\n",
      "Epoch 5/5\n",
      "956/956 [==============================] - 1s 1ms/step - loss: 0.1027 - acc: 0.9519 - val_loss: 1.2811 - val_acc: 0.8828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b327484160>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=200, epochs=5, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 196us/step\n",
      "Test accuracy: 0.8828451633453369\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy of model on validation data. It's not AUC but it's something at least!\n",
    "score, acc = model.evaluate(X_val, y_val, batch_size=300)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br id=\"prediction\">\n",
    "# 4. Prediction\n",
    "The model is now ready to predict the test set classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict X_test\n",
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result for submission\n",
    "result = pd.DataFrame()\n",
    "result['vid_id'] = test.vid_id\n",
    "result['is_turkey'] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result.to_csv('submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the Kaggle competition, this model gave me score of 0.95657."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
